# Test GPU allocation via SUNK scheduler
# Based on: https://docs.coreweave.com/docs/products/sunk/run_workloads/schedule-kubernetes-pods
apiVersion: v1
kind: Pod
metadata:
  name: gpu-sunk-test
  namespace: tenant-slurm
  annotations:
    sunk.coreweave.com/account: root
    sunk.coreweave.com/exclusive: "user"  # Allow sharing between K8s pods
    sunk.coreweave.com/comment: "Kubetorch GPU test"
spec:
  schedulerName: tenant-slurm-slurm-scheduler
  restartPolicy: Never
  terminationGracePeriodSeconds: 5
  containers:
    - name: gpu-test
      image: nvcr.io/nvidia/pytorch:24.08-py3
      command: ["/bin/bash", "-c"]
      args:
        - |
          python3 -c "
          import torch
          print('CUDA available:', torch.cuda.is_available())
          if torch.cuda.is_available():
              print('GPU count:', torch.cuda.device_count())
              print('GPU name:', torch.cuda.get_device_name(0))
              x = torch.randn(1000, 1000, device='cuda')
              y = torch.matmul(x, x)
              print('Test matmul successful, shape:', y.shape)
          "
          sleep 10
      resources:
        requests:
          cpu: "8"
          memory: "64Gi"
          nvidia.com/gpu: "1"
        limits:
          memory: "128Gi"
          nvidia.com/gpu: "1"
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: gpu.nvidia.com/model
                operator: In
                values:
                  - B200

